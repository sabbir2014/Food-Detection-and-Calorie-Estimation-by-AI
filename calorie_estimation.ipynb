{"cells":[{"cell_type":"markdown","metadata":{"id":"-76upuqnT0dO"},"source":["# **Project name:** Calorie estimation of various foods \n","\n"]},{"cell_type":"markdown","metadata":{"id":"LB54J0sBUYAP"},"source":["# Problem statement: \n","Given a collection of food images with a calibration item thumb annotated with the food name and an unlabeled set of food images from the same category of food, identify the food and estimate the amount and calories consumed."]},{"cell_type":"markdown","metadata":{"id":"zoW3_RagWZVG"},"source":["**Steps for building this system:**\n","\n","\n","1.   Review over existing works\n","\n","*   [An Image Procesing Approach for Calorie\n","Intake Measurement](https://www.researchgate.net/profile/Shervin-Shirmohammadi-2/publication/241633012_An_Image_Processing_Approach_for_Calorie_Intake_Measurement/links/5ab5e7b0aca2722b97cad998/An-Image-Processing-Approach-for-Calorie-Intake-Measurement.pdf)\n","\n","\n","*   [Food calorie estimation using machine learning and image processing](https://d1wqtxts1xzle7.cloudfront.net/59165453/V5I2-193520190507-93463-zup54f-with-cover-page-v2.pdf?Expires=1647348749\u0026Signature=aqrQzNeQwytLCh1bzlAbrecTdC23E9Gbl~xFS1rb4KIvvjpKiFMPAST5JP6gEXo~5H6GeirlEsjSkR5yFacpEKpz2AwGuaWwBkQOpA0ugZww6HCX~zmicGg82J6gnTvTw0ZtreweX4Z30Nj4HKBywwpXS5sceG~-Afwxekco2KY1iFir~290bWCa9z5q4XGT6BFSSjy6O705q6h5tqLfww1edi-XGlwHsLSEXJPj9ZCsUkvX~zb9Y5KRFQJhGwwzyZy~VLFSHq1qpmRuAZbnCP7Ju33f668LQsj8Q4jc~SrFH~l6-tTKdUWIXphRYgiESelYI60wdaL0Qfe6WtnxBw__\u0026Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)\n","\n","*   [Image Processing Based Classification of Energy Sources in Eatables Using Artificial Intelligence](https://www.annalsofrscb.ro/index.php/journal/article/download/2277/1900)\n","\n","\n","*  [Application of Deep Learning in Food: A Review](https://sci-hub.hkvisa.net/10.1111/1541-4337.12492) \n","\n","\n","\n","*  [Deep Learning-Based Food Calorie Estimation Method in Dietary Assessment](https://github.com/Liang-yc/CalorieEstimation/tree/master/faster_rcnn-master) \n","\n","\n","2. Dataset: \n","\n","*   [Fruit360](https://www.kaggle.com/moltean/fruits?select=fruits-360-original-size)\n","\n","*  [FooDD](https://drive.google.com/drive/folders/1rmVS_n6P1859trFxKhY7iHVywjTIRYwn) \n","\n","\n","*   [ECUSTFD](https://github.com/Liang-yc/ECUSTFD-resized-)\n","\n","\n","\n","\n","3.  Classification and detection of food images via algortihms: \n","\n","\n","*  Histogram of Oriented Gradients (HOG) Feature Descriptor\n","\n","*  Region-based Convolutional Neural Networks (R-CNN) \n","\n","*  Region-based Fully Convolutional Network (R-FCN) \n","\n","\n","*  Single Shot Detector (SSD)\n","\n","*  Spatial Pyramid Pooling (SPP-net) \n","\n","*  YOLO (You Only Look Once) e.t.c. \n","\n","We are still looking for suitable algorithms for detection.\n","\n","\n","4. Now there are some challanges regarding calorie estimation. First challenge is to predict ingredients like predicting type of pizza from various type. Then to predict its weight. Now weight is calculated as, \n","\n","\n","\n","\u003e **M = V.D**\n","\n","Where M is mass, V is volume and D is density. Now getting volume from 2d image is very difficult. And still there is no significant progress in this field. So we opted a different approach. We will use image segmentation methods for this. To acquire the contour of the fruit and the contour of the thumb, a combination of approaches including canny edge detection, watershed segmentation, morphological operators, and Otsu's method were utilized to segment the food item. For calibrating purposes, we use the thumb finger. While taking the snapshot, the thumb is put next to the dish, giving us an indication of the real-life size of the food item and assisting in accurate volume estimation. Here is a demo of our image segmentation: \n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"gQe5EPg7lnLj"},"source":["**Importing libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1647362735500,"user":{"displayName":"mehedi hasan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04439352825899445020"},"user_tz":-360},"id":"fdbCJpm8li9-"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import os\n","from google.colab.patches import cv2_imshow"]},{"cell_type":"markdown","metadata":{"id":"EVrnTe4tl25K"},"source":["**Defining function**"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":363,"status":"ok","timestamp":1647362741572,"user":{"displayName":"mehedi hasan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04439352825899445020"},"user_tz":-360},"id":"cJxF1po0l2Xe"},"outputs":[],"source":["def getAreaOfFood(img1):\n","    data=os.path.join(os.getcwd(),\"images\")\n","    if os.path.exists(data):\n","        print('folder exist for images at ',data)\n","    else:\n","        os.mkdir(data)\n","        print('folder created for images at ',data)\n","        \n","    cv2.imwrite('{}\\\\1 original image.jpg'.format(data),img1)\n","    img = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","    cv2.imwrite('{}\\\\2 original image BGR2GRAY.jpg'.format(data),img)\n","    cv2_imshow(img)\n","    img_filt = cv2.medianBlur( img, 5)\n","    cv2.imwrite('{}\\\\3 img_filt.jpg'.format(data),img_filt)\n","    cv2_imshow(img_filt)\n","    img_th = cv2.adaptiveThreshold(img_filt,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,21,2)\n","    cv2.imwrite('{}\\\\4 img_th.jpg'.format(data),img_th)\n","    cv2_imshow(img_th)\n","    contours, hierarchy = cv2.findContours(img_th, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) #make change here\n","\n","\n","\t# find contours. sort. and find the biggest contour. the biggest contour corresponds to the plate and fruit.\n","    mask = np.zeros(img.shape, np.uint8)\n","    largest_areas = sorted(contours, key=cv2.contourArea)\n","    cv2.drawContours(mask, [largest_areas[-1]], 0, (255,255,255,255), -1)\n","    cv2.imwrite('{}\\\\5 mask.jpg'.format(data),mask)\n","    cv2_imshow(mask)\n","    img_bigcontour = cv2.bitwise_and(img1,img1,mask = mask)\n","    cv2.imwrite('{}\\\\6 img_bigcontour.jpg'.format(data),img_bigcontour)\n","    cv2_imshow(img_bigcontour)\n","\n","\t# convert to hsv. otsu threshold in s to remove plate\n","    hsv_img = cv2.cvtColor(img_bigcontour, cv2.COLOR_BGR2HSV)\n","    cv2.imwrite('{}\\\\7 hsv_img.jpg'.format(data),hsv_img)\n","    cv2_imshow(hsv_img)\n","    h,s,v = cv2.split(hsv_img)\n","    mask_plate = cv2.inRange(hsv_img, np.array([0,0,50]), np.array([200,90,250]))\n","    cv2.imwrite('{}\\\\8 mask_plate.jpg'.format(data),mask_plate)\n","    cv2_imshow(mask_plate)\n","    mask_not_plate = cv2.bitwise_not(mask_plate)\n","    cv2.imwrite('{}\\\\9 mask_not_plate.jpg'.format(data),mask_not_plate)\n","    cv2_imshow(mask_not_plate)\n","    fruit_skin = cv2.bitwise_and(img_bigcontour,img_bigcontour,mask = mask_not_plate)\n","    cv2.imwrite('{}\\\\10 fruit_skin.jpg'.format(data),fruit_skin)\n","    cv2_imshow(fruit_skin)\n","\n","\t#convert to hsv to detect and remove skin pixels\n","    hsv_img = cv2.cvtColor(fruit_skin, cv2.COLOR_BGR2HSV)\n","    cv2.imwrite('{}\\\\11 hsv_img.jpg'.format(data),hsv_img)\n","    cv2_imshow(hsv_img)\n","    skin = cv2.inRange(hsv_img, np.array([0,10,60]), np.array([10,160,255])) #Scalar(0, 10, 60), Scalar(20, 150, 255)\n","    cv2.imwrite('{}\\\\12 skin.jpg'.format(data),skin)\n","    cv2_imshow(skin)\n","    not_skin = cv2.bitwise_not(skin); #invert skin and black\n","    cv2.imwrite('{}\\\\13 not_skin.jpg'.format(data),not_skin)\n","    cv2_imshow(not_skin)\n","    fruit = cv2.bitwise_and(fruit_skin,fruit_skin,mask = not_skin) #get only fruit pixels\n","    cv2.imwrite('{}\\\\14 fruit.jpg'.format(data),fruit)\n","    cv2_imshow(fruit)\n","    \n","    fruit_bw = cv2.cvtColor(fruit, cv2.COLOR_BGR2GRAY)\n","    cv2.imwrite('{}\\\\15 fruit_bw.jpg'.format(data),fruit_bw)\n","    cv2_imshow(fruit_bw)\n","    fruit_bin = cv2.inRange(fruit_bw, 10, 255) #binary of fruit\n","    cv2.imwrite('{}\\\\16 fruit_bw.jpg'.format(data),fruit_bin)\n","    cv2_imshow(fruit_bin)\n","\n","\t#erode before finding contours\n","    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n","    erode_fruit = cv2.erode(fruit_bin,kernel,iterations = 1)\n","    cv2.imwrite('{}\\\\17 erode_fruit.jpg'.format(data),erode_fruit)\n","    cv2_imshow(erode_fruit)\n","\n","\t#find largest contour since that will be the fruit\n","    img_th = cv2.adaptiveThreshold(erode_fruit,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n","    cv2.imwrite('{}\\\\18 img_th.jpg'.format(data),img_th)\n","    cv2_imshow(img_th)\n","    contours, hierarchy = cv2.findContours(img_th, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","    mask_fruit = np.zeros(fruit_bin.shape, np.uint8)\n","    largest_areas = sorted(contours, key=cv2.contourArea)\n","    cv2.drawContours(mask_fruit, [largest_areas[-2]], 0, (255,255,255), -1)\n","    cv2.imwrite('{}\\\\19 mask_fruit.jpg'.format(data),mask_fruit)\n","    cv2_imshow(mask_fruit)\n","\n","\t#dilate now\n","    kernel2 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n","    mask_fruit2 = cv2.dilate(mask_fruit,kernel2,iterations = 1)\n","    cv2.imwrite('{}\\\\20 mask_fruit2.jpg'.format(data),mask_fruit2)\n","    cv2_imshow(mask_fruit2)\n","    fruit_final = cv2.bitwise_and(img1,img1,mask = mask_fruit2)\n","    cv2.imwrite('{}\\\\21 fruit_final.jpg'.format(data),fruit_final)\n","    cv2_imshow(fruit_final)\n","    \n","\t#find area of fruit\n","    img_th = cv2.adaptiveThreshold(mask_fruit2,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n","    cv2.imwrite('{}\\\\22 img_th.jpg'.format(data),img_th)\n","    cv2_imshow(img_th)\n","    contours, hierarchy = cv2.findContours(img_th, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","    largest_areas = sorted(contours, key=cv2.contourArea)\n","    fruit_contour = largest_areas[-2]\n","    fruit_area = cv2.contourArea(fruit_contour)\n","\n","\t\n","\t#finding the area of skin. find area of biggest contour\n","    skin2 = skin - mask_fruit2\n","    cv2.imwrite('{}\\\\23 skin2.jpg'.format(data),skin2)\n","    cv2_imshow(skin2)\n","\t#erode before finding contours\n","    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n","    skin_e = cv2.erode(skin2,kernel,iterations = 1)\n","    cv2.imwrite('{}\\\\24 skin_e .jpg'.format(data),skin_e )\n","    cv2_imshow(skin_e)\n","    img_th = cv2.adaptiveThreshold(skin_e,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n","    cv2.imwrite('{}\\\\25 img_th.jpg'.format(data),img_th)\n","    cv2_imshow(img_th)\n","    contours, hierarchy = cv2.findContours(img_th, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n","    mask_skin = np.zeros(skin.shape, np.uint8)\n","    largest_areas = sorted(contours, key=cv2.contourArea)\n","    cv2.drawContours(mask_skin, [largest_areas[-2]], 0, (255,255,255), -1)\n","    cv2.imwrite('{}\\\\26 mask_skin.jpg'.format(data),mask_skin)\n","    cv2_imshow(mask_skin)\n","    \n","    \n","    skin_rect = cv2.minAreaRect(largest_areas[-2])\n","    box = cv2.boxPoints(skin_rect)\n","    box = np.int0(box)\n","    mask_skin2 = np.zeros(skin.shape, np.uint8)\n","    cv2.drawContours(mask_skin2,[box],0,(255,255,255), -1)\n","    cv2.imwrite('{}\\\\27 mask_skin2.jpg'.format(data),mask_skin2)\n","    cv2_imshow(mask_skin2)\n","    \n","    pix_height = max(skin_rect[1])\n","    pix_to_cm_multiplier = 5.0/pix_height\n","    skin_area = cv2.contourArea(box)\n","    \n","    \n","    return fruit_area,fruit_bin ,fruit_final,skin_area, fruit_contour, pix_to_cm_multiplier"]},{"cell_type":"markdown","metadata":{"id":"b0TE7LFynAKO"},"source":["**Connecting Google drive to import image**"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22588,"status":"ok","timestamp":1647362770274,"user":{"displayName":"mehedi hasan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04439352825899445020"},"user_tz":-360},"id":"83FxBFhZnGin","outputId":"6a627339-3cdf-4070-cb1f-dd4a505cb1a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/gdrive\")"]},{"cell_type":"markdown","metadata":{"id":"10hVIeFrmkcO"},"source":["**Testing these segementation**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"output_embedded_package_id":"1ZxxHY3zGpDVMhQDA_eJBfGP7RrPCCy2j"},"id":"dD-5p47lmpqS","outputId":"7484b6ae-3e44-433e-8d7c-b50be2ce5440"},"outputs":[],"source":["    import cv2\n","    img1 = cv2.imread(r\"/content/gdrive/MyDrive/test/1 (21).jpg\")\n","    cv2_imshow(img1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1TYhTglRoYYHh9K3OkmY4Qcol4mKMR-a-"},"executionInfo":{"elapsed":23041,"status":"ok","timestamp":1647352360843,"user":{"displayName":"mehedi hasan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"04439352825899445020"},"user_tz":-360},"id":"7_WD1ympwpP2","outputId":"91464ae2-1c8c-4c2a-8625-033aecbe1a3a"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["    img1 = cv2.imread(r\"/content/gdrive/MyDrive/test/1 (21).jpg\")\n","    img = cv2.resize(img1,(1000,1000))\n","    area, bin_fruit, img_fruit, skin_area, fruit_contour, pix_to_cm_multiplier = getAreaOfFood(img)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNWipruuV7e2e6Mz1ojydYH","collapsed_sections":[],"name":"calorie_estimation.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}